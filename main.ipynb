{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the train set \n",
    "Because it's too large, we have to process the .jsonl file in chunks. This has been done previously by someone online that provided the resulting file called \"final_output.parquet\". \n",
    "\n",
    "Details of the processing : \n",
    "Iof loading the entire file into memory, we read it line by line using a batch processing approach to store data in smaller Parquet files. \n",
    "\n",
    "Each line represents a session containing multiple events. The function extracts the session_id and attaches it to the event. \n",
    "Once all rows are collected, the data is saved as a Parquet file, an efficient storage format. Then, it resets the batch and continues processing it until the eof the file. \n",
    "\n",
    "Afterwards, all Parquet files are merged into one single file, the \"final_output.parquet\". \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.dask_expr._collection.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd \n",
    "# Using Dask iof Pandas allows processing very large files without loading everything into memory \n",
    "\n",
    "parquet_file = \"data/final_output.parquet\"\n",
    "data = dd.read_parquet(parquet_file)\n",
    "print(type(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "      <th>session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1489275</td>\n",
       "      <td>1660039772288</td>\n",
       "      <td>clicks</td>\n",
       "      <td>5899776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1826552</td>\n",
       "      <td>1660043110728</td>\n",
       "      <td>clicks</td>\n",
       "      <td>5899776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1632206</td>\n",
       "      <td>1660048043858</td>\n",
       "      <td>clicks</td>\n",
       "      <td>5899776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1531634</td>\n",
       "      <td>1660048104470</td>\n",
       "      <td>clicks</td>\n",
       "      <td>5899776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1086210</td>\n",
       "      <td>1660039772327</td>\n",
       "      <td>clicks</td>\n",
       "      <td>5899777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       aid             ts    type  session\n",
       "0  1489275  1660039772288  clicks  5899776\n",
       "1  1826552  1660043110728  clicks  5899776\n",
       "2  1632206  1660048043858  clicks  5899776\n",
       "3  1531634  1660048104470  clicks  5899776\n",
       "4  1086210  1660039772327  clicks  5899777"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the test.jsonl file\n",
    "test_file = \"data/test.jsonl\"\n",
    "# Step 1: Read the JSONL file directly\n",
    "with open(test_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Step 2: Expand the nested 'events' column\n",
    "flattened_data = []\n",
    "for record in data:\n",
    "    session_id = record[\"session\"]\n",
    "    for event in record[\"events\"]:\n",
    "        event[\"session\"] = session_id  # Add session ID to each event\n",
    "        flattened_data.append(event)\n",
    "\n",
    "# Step 3: Convert to DataFrame\n",
    "test_df = pd.DataFrame(flattened_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "      <th>session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12243771</th>\n",
       "      <td>1117003</td>\n",
       "      <td>1660679104743</td>\n",
       "      <td>clicks</td>\n",
       "      <td>4200398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12243772</th>\n",
       "      <td>1117003</td>\n",
       "      <td>1660679120851</td>\n",
       "      <td>carts</td>\n",
       "      <td>4200398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12243773</th>\n",
       "      <td>24174</td>\n",
       "      <td>1660679253624</td>\n",
       "      <td>clicks</td>\n",
       "      <td>4200398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12243774</th>\n",
       "      <td>24174</td>\n",
       "      <td>1660679272894</td>\n",
       "      <td>carts</td>\n",
       "      <td>4200398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12243775</th>\n",
       "      <td>1391615</td>\n",
       "      <td>1660682317258</td>\n",
       "      <td>clicks</td>\n",
       "      <td>4200398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              aid             ts    type  session\n",
       "12243771  1117003  1660679104743  clicks  4200398\n",
       "12243772  1117003  1660679120851   carts  4200398\n",
       "12243773    24174  1660679253624  clicks  4200398\n",
       "12243774    24174  1660679272894   carts  4200398\n",
       "12243775  1391615  1660682317258  clicks  4200398"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aid                  int64\n",
       "ts                   int64\n",
       "type       string[pyarrow]\n",
       "session              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from ydata_profiling import ProfileReport\\ndf_sample = train_df.sample(frac=0.2).compute()\\n\\nprofile = ProfileReport(df_sample, title=\"Profiling-Report\")\\nprofile.to_file(\"Profiling-Report.html\") \"\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from ydata_profiling import ProfileReport\n",
    "df_sample = train_df.sample(frac=0.2).compute()\n",
    "\n",
    "profile = ProfileReport(df_sample, title=\"Profiling-Report\")\n",
    "profile.to_file(\"Profiling-Report.html\") \"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "      <th>session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1489275</td>\n",
       "      <td>1660039772288</td>\n",
       "      <td>clicks</td>\n",
       "      <td>5899776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1826552</td>\n",
       "      <td>1660043110728</td>\n",
       "      <td>clicks</td>\n",
       "      <td>5899776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1632206</td>\n",
       "      <td>1660048043858</td>\n",
       "      <td>clicks</td>\n",
       "      <td>5899776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1531634</td>\n",
       "      <td>1660048104470</td>\n",
       "      <td>clicks</td>\n",
       "      <td>5899776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1086210</td>\n",
       "      <td>1660039772327</td>\n",
       "      <td>clicks</td>\n",
       "      <td>5899777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       aid             ts    type  session\n",
       "0  1489275  1660039772288  clicks  5899776\n",
       "1  1826552  1660043110728  clicks  5899776\n",
       "2  1632206  1660048043858  clicks  5899776\n",
       "3  1531634  1660048104470  clicks  5899776\n",
       "4  1086210  1660039772327  clicks  5899777"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train_df \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown types found: Dask Series Structure:\n",
      "npartitions=14\n",
      "    string\n",
      "       ...\n",
      "     ...  \n",
      "       ...\n",
      "       ...\n",
      "Dask Name: unique, 7 expressions\n",
      "Expr=Unique(frame=Loc(frame=ReadParquetFSSpec(46fde82)['type'], iindexer=~ Isin(frame=ReadParquetFSSpec(46fde82)['type'], values=_DelayedExpr(Delayed('delayed-214f12dd7839a27aad04324384ee5121')))))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\dask_expr\\_collection.py:4204: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('type', 'float64'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aid</th>\n",
       "      <th>ts</th>\n",
       "      <th>type</th>\n",
       "      <th>session</th>\n",
       "      <th>eventStrength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1489275</td>\n",
       "      <td>1660039772288</td>\n",
       "      <td>clicks</td>\n",
       "      <td>5899776</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1826552</td>\n",
       "      <td>1660043110728</td>\n",
       "      <td>clicks</td>\n",
       "      <td>5899776</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1632206</td>\n",
       "      <td>1660048043858</td>\n",
       "      <td>clicks</td>\n",
       "      <td>5899776</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1531634</td>\n",
       "      <td>1660048104470</td>\n",
       "      <td>clicks</td>\n",
       "      <td>5899776</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1086210</td>\n",
       "      <td>1660039772327</td>\n",
       "      <td>clicks</td>\n",
       "      <td>5899777</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       aid             ts    type  session  eventStrength\n",
       "0  1489275  1660039772288  clicks  5899776            1.0\n",
       "1  1826552  1660043110728  clicks  5899776            1.0\n",
       "2  1632206  1660048043858  clicks  5899776            1.0\n",
       "3  1531634  1660048104470  clicks  5899776            1.0\n",
       "4  1086210  1660039772327  clicks  5899777            1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clearly define mapping\n",
    "event_type_strength = {\n",
    "    'clicks': 1.0,\n",
    "    'add_to_cart': 2.0, \n",
    "    'order': 3.0,  \n",
    "}\n",
    "\n",
    "# Check unknown types first (recommended)\n",
    "unknown_types = df.loc[~df['type'].isin(event_type_strength), 'type'].unique()\n",
    "print(\"Unknown types found:\", unknown_types)\n",
    "\n",
    "# Apply mapping with safety net\n",
    "df['eventStrength'] = df['type'].map(event_type_strength).fillna(0.0)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommender systems have a problem known as user cold-start, in which is hard do provide personalized recommendations for users with none or a very few number of consumed items, due to the lack of information to model their preferences.\n",
    "For this reason, we are keeping in the dataset only users with at least 5 interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# users: 12899779\n",
      "# users with at least 5 interactions: 6091807\n"
     ]
    }
   ],
   "source": [
    "users_interactions_count_df = df.groupby(['session', 'aid']).size().groupby('session').size()\n",
    "print('# users: %d' % len(users_interactions_count_df))\n",
    "users_with_enough_interactions_df = users_interactions_count_df[users_interactions_count_df >= 5].reset_index()[['session']]\n",
    "print('# users with at least 5 interactions: %d' % len(users_with_enough_interactions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session\n",
       "0        0\n",
       "1        1\n",
       "2        2\n",
       "3        3\n",
       "4        4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_with_enough_interactions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of interactions from users with at least 5 interactions: 191678570\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 510. MiB for an array with shape (66838606,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# of interactions from users with at least 5 interactions: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(filtered_df))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Save the filtered dataset as Parquet (efficient for large data)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mfiltered_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfiltered_data.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiltered data saved as Parquet.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\dask_expr\\_collection.py:3310\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[1;34m(self, path, **kwargs)\u001b[0m\n\u001b[0;32m   3307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_parquet\u001b[39m(\u001b[38;5;28mself\u001b[39m, path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   3308\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataframe\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdask_expr\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[1;32m-> 3310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\dask_expr\\io\\parquet.py:655\u001b[0m, in \u001b[0;36mto_parquet\u001b[1;34m(df, path, compression, write_index, append, overwrite, ignore_divisions, partition_on, storage_options, custom_metadata, write_metadata_file, compute, compute_kwargs, schema, name_function, filesystem, engine, **kwargs)\u001b[0m\n\u001b[0;32m    634\u001b[0m     out \u001b[38;5;241m=\u001b[39m new_collection(\n\u001b[0;32m    635\u001b[0m         ToParquet(\n\u001b[0;32m    636\u001b[0m             df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    651\u001b[0m         )\n\u001b[0;32m    652\u001b[0m     )\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute:\n\u001b[1;32m--> 655\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcompute_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;66;03m# Invalidate the filesystem listing cache for the output path after write.\u001b[39;00m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;66;03m# We do this before returning, even if `compute=False`. This helps ensure\u001b[39;00m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;66;03m# that reading files that were just written succeeds.\u001b[39;00m\n\u001b[0;32m    660\u001b[0m fs\u001b[38;5;241m.\u001b[39minvalidate_cache(path)\n",
      "File \u001b[1;32mc:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\dask_expr\\_collection.py:489\u001b[0m, in \u001b[0;36mFrameBase.compute\u001b[1;34m(self, fuse, concatenate, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mrepartition(npartitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    488\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39moptimize(fuse\u001b[38;5;241m=\u001b[39mfuse)\n\u001b[1;32m--> 489\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDaskMethodsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\base.py:374\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    351\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \n\u001b[0;32m    353\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 374\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\base.py:662\u001b[0m, in \u001b[0;36mcompute\u001b[1;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[0;32m    659\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m    661\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m--> 662\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[1;32mc:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\dask\\dataframe\\dask_expr\\_shuffle.py:1301\u001b[0m, in \u001b[0;36mSetIndexBlockwise.operation\u001b[1;34m(df, new_divisions, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1299\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moperation\u001b[39m(df, \u001b[38;5;241m*\u001b[39margs, new_divisions, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 1301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mathi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:155\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    149\u001b[0m out_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(out_shape_)\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous \u001b[38;5;129;01mand\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;66;03m# minor tweak that can make an order-of-magnitude difference\u001b[39;00m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# for dataframes initialized directly from 2-d ndarrays\u001b[39;00m\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;66;03m# (s.t. df.values is c-contiguous and df._mgr.blocks[0] is its\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# f-contiguous transpose)\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mF\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 510. MiB for an array with shape (66838606,) and data type int64"
     ]
    }
   ],
   "source": [
    "# Merge to keep only relevant interactions\n",
    "filtered_df = df.merge(users_with_enough_interactions_df[[\"session\"]], \n",
    "                        how=\"right\", \n",
    "                        on=\"session\")\n",
    "\n",
    "print(\"# of interactions from users with at least 5 interactions: %d\" % len(filtered_df))\n",
    "\n",
    "# Save the filtered dataset as Parquet (efficient for large data)\n",
    "filtered_df.to_parquet(\"filtered_data.parquet\", index=False)\n",
    "\n",
    "print(\"Filtered data saved as Parquet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
